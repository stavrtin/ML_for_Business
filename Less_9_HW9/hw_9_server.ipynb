{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d21e976f-5857-4275-938b-76f961e67342",
   "metadata": {},
   "source": [
    "# ДЗ 9. Просто Сервер, считываем готовую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf1c39f-9a09-47da-b144-d1aa6a7031e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import dill\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#working with text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#normalizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "\n",
    "#imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ce5c625-9d76-461e-9731-e8af9f9c3ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем обученные модели\n",
    "with open('logreg_pipeline.dill', 'rb') as in_strm:\n",
    "    model = dill.load(in_strm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f392e65-9143-4b67-b9ce-b6a4586e170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [18/Aug/2022 15:44:30] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Aug/2022 15:45:22] \"POST //predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stylect is a dynamic startup that helps helps women discover and buy shoes. We’re a small team based in London that has previously worked at Google, Techstars, Pixelmator and Rocket Internet.We place a high premium on simplicity no matter what we’re working on (i.e. design, programming, marketing). We’re also a team that ships fast. We built version 1 of our app in a week, the next release (built in a month) was featured in the Apple Appstore Italy as a best new fashion app. Fast release cycles are challenging, but also very fun - which is why we love them. As we’ve grown, the projects that we’re working on have grown both in scale and in technical complexity.  Stylect is looking for someone who can help us improve our backend which gathers product data; analyses/categorizes it; and shows it to thousands of users daily. Each step in the process has unique challenges that demands a strong technical background.\n",
      "OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Aug/2022 15:47:41] \"POST //predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stylect is a dynamic startup that helps helps women discover and buy shoes. We’re a small team based in London that has previously worked at Google, Techstars, Pixelmator and Rocket Internet.We place a high premium on simplicity no matter what we’re working on (i.e. design, programming, marketing). We’re also a team that ships fast. We built version 1 of our app in a week, the next release (built in a month) was featured in the Apple Appstore Italy as a best new fashion app. Fast release cycles are challenging, but also very fun - which is why we love them. As we’ve grown, the projects that we’re working on have grown both in scale and in technical complexity.  Stylect is looking for someone who can help us improve our backend which gathers product data; analyses/categorizes it; and shows it to thousands of users daily. Each step in the process has unique challenges that demands a strong technical background.\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Обработчики и запуск Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def general():\n",
    "    return \"Welcome to prediction process\"\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = {\"success\": False}\n",
    "\n",
    "    # ensure an image was properly uploaded to our endpoint\n",
    "    description, company_profile, benefits = \"\", \"\", \"\"\n",
    "    request_json = request.get_json()\n",
    "    \n",
    "    if request_json[\"description\"]:\n",
    "        description = request_json['description']\n",
    "    \n",
    "    if request_json[\"company_profile\"]:\n",
    "        company_profile = request_json['company_profile']\n",
    "                \n",
    "    if request_json[\"benefits\"]:\n",
    "        benefits = request_json['benefits']\n",
    "    \n",
    "    print(description)  \n",
    "    preds = model.predict_proba(pd.DataFrame({\"description\": [description],\n",
    "                                              \"company_profile\": [company_profile],\n",
    "                                              \"benefits\": [benefits]}))\n",
    "    data[\"predictions\"] = preds[:, 1][0]\n",
    "    data[\"description\"] = description\n",
    "        # indicate that the request was a success\n",
    "    data[\"success\"] = True\n",
    "    print('OK')\n",
    "\n",
    "        # return the data dictionary as a JSON response\n",
    "    return jsonify(data)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199626e-17c6-4d12-b625-0f3fc4d002d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff622774-bfbc-4bdf-b448-4be5bb56267d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
